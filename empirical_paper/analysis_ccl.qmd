---
title: 'Poverty is associated with both risk avoidance and risk taking: empirical evidence for the desperation threshold model from the UK and France'
subtitle: "This chapter is based on: \n de Courson, B., Frankenhuis, W. E., & Nettle, D. (2025). Poverty is associated with both risk avoidance and risk taking: empirical evidence for the desperation threshold model from the UK and France. Proceedings B, 292(2040), 20242071."

format:
  pdf
bibliography: references.bib
knitr:
  opts_chunk:
    warning: false
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

```{r include=FALSE, message=FALSE}
library(stringr)
library(lme4)
library(lmerTest)
library(ggh4x)
library(table1)
library(glue)
library(DescTools)
library(htmlTable)
library(flextable)
library(ggplot2)
library(Rmisc)
library(psy)
library(tibble)
library(knitr)
library(dplyr)
library(knitr)
library(gtools)
library(rbbt)
library(cowplot)

stars.pval2 = function(x){
  a = stars.pval(x)
  z = which(a == ".")
  a[z] = " "
  return(a)
}
```

\newpage

## Abstract

In situations of poverty, do people take more or less risk? Some theories state that poverty makes people 'vulnerable': they cannot buffer against losses, and therefore avoid risk. Yet, other theories state the opposite: poverty makes people 'desperate': they have little to lose, and therefore take risks. Each theory has some support: most studies find a negative association between resources and risk taking, but risky behaviors such as crime and gambling are more common in deprived populations. Here, we test the 'desperation threshold' model, which integrates both hypotheses. We assume that people attempt to stay above a critical level of resources, representing their 'basic needs'. Just above this threshold, people have too much to lose, and should avoid risk. Below, they have little to lose, and should take risks. We conducted preregistered tests of this prediction using data of 472 adults over the age of 25 in France and the UK, who completed a survey once a month for 12 months. We found that risk taking followed a V-shape against subjective resources, but not objective resources. Next, we tested whether risk taking varies more among people with fewer resources, as our model predicts, and found strong evidence for this prediction.

## Introduction

In situations of poverty, do individuals tend to take more or fewer risks? On this question, there are, as Banerjee puts it, "at least two distinct and, prima facie, inconsistent views" [@banerjee2004]. The first is that poverty makes individuals 'vulnerable': they have barely enough to make ends meet and would suffer too much from a resource loss. Therefore, they avoid risk. The second is that poverty makes individuals 'desperate': they have little to lose, and are ready to gamble to have a chance to get out of poverty, since their situation cannot get much worse. Therefore, they take more risks. Even though these two views predict opposite associations between levels of resources and risk taking, both can be found in theories across the social sciences [for examples of the view that poverty increases risk taking, see @ellis2012; @griskevicius2011; @hill1997; @daly2001; @banerjee1994; for examples of the view that poverty decreases risk taking, see @haushofer2014; @baumard2019; @gollier2002; @banerjee2007]. Both views have also been used to make sense of empirical findings. The idea that people in poverty avoid risk has been invoked to explain the lack of professional specialization [@banerjee2007], a reluctance to adopt new technologies or to invest in education [@haushofer2014], and even the persistence of poverty [@yesuf2009; @haushofer2014]. On the other hand, the idea that people in poverty have 'little to lose', and therefore seek risk, has been invoked [@brezina2008; @griskevicius2011; @daly2001] to explain higher prevalence of crime [@hsieh1993] and gambling [@wardle2014] in deprived populations.

The empirical record is also mixed [@kish-gephart2017; @tanaka2010; @vieider2012; @haushofer]. In high-income countries, most cross-sectional studies have found that individuals with a lower income or wealth take fewer risks in experimental gambling tasks [e.g., @guiso2008; @dohmen2011; @eckel2012;  for a review, see @sheehy-skeffington2017]. In low-income countries, some studies have also reported less risk taking [@yesuf2009], but others found no association [@binswanger1980; @cardenas2013; @mosley2005], or even more risk taking. For instance, the poorest Indian farmers were found to be extremely willing to take risks [@maertens2014]. Among poor Madagascar farmers, food insecurity was the best positive predictor of risk taking in hypothetical gambles [@tucker2012]. Another study used the choice between drought-resistant camels and more productive but riskier small livestock, as a proxy of risk taking among four herder groups [@mace1990]. In three of the four groups, the poorest households kept mostly riskier small livestock. To sum up, there is a crucial inconsistency: two bodies of work propose and document exactly opposite associations between poverty and risk taking. Both views are intuitively appealing, and both have support in the empirical record. Both are relevant to explaining key social phenomena, such as occupational choices and crime.

Optimal foraging theory, and risk-sensitive foraging in particular, can resolve this conundrum [@decourson2021; @decoursonWhyViolenceHigh2023b]. In a scenario first modeled by @stephens1981, a 'small bird in winter' aims to acquire enough calories to get through the night. Just above the 'starvation threshold' -- where the bird is likely to survive, but only just -- it should avoid risks, so as to not fall below it. However, below this threshold, it should take risks, to have a chance to keep its head above water. Thus, low compared to high energetic resources will be associated with either greater risk avoidance or greater risk taking, depending on how low they are. Analogous applications of this idea to humans in situations of resource scarcity have emerged independently in disparate fields of research, including psychology [@barclay; @mishra2010], agricultural economics [@roumasset1971 ; @kunreuther1974], development economics [@lybbert2011], anthropology [@winterhalder1999] and political science [@scott1977]. In our papers, we [@decourson2021; @decoursonWhyViolenceHigh2023b] applied this same logic to criminal behaviour in situations of poverty. We assumed that individuals have a 'desperation threshold' representing 'basic needs' that they try to always meet. We elaborate the desperation threshold model and its predictions in section 2.

The desperation threshold model has been tested in lab experiments [@mishra2010; @pietras2001; @pietras2006; @pietras2008; @deditius-island2007; @rode1999; @radkani2023]. Participants -- students or online participants from North America or the United Kindgom -- typically play a game that includes an artificial threshold, such as a minimum number of points needed to obtain a monetary payoff at the end of the game. Participants tend to behave in accordance with the theoretical prediction, taking fewer risks when their resource level is above the threshold, and more below. These findings suggest that people are able to adjust their behavior when confronted with a threshold. But they tell us little about behavior in natural environments. Do such thresholds exist outside the lab? Do they affect the behavior of a sizeable fraction of the population?

Evidence for the predictions of the desperation threshold in real-world settings is scarce, in part because cross-sectional studies are often ill-suited to testing threshold effects. Such studies tend to model risk taking as a linear function of resources, whereas the desperation threshold predicts a non-linear mapping (a U- or V-shape): poverty should reduce risk taking up to some point, and then increase it. Nevertheless, several studies are informative. For instance, [@barsky1997] estimated risk taking by quintiles of income and wealth in the Health and Retirement Study, a representative panel of Americans over age 50. Consistent with the desperation threshold, people in the poorest and the richest quintiles, whether measured in income or in wealth, were ready to take the most risks. Recently, Akesaka et al. [@akesaka2023] documented in the same dataset that those who strongly depended on social security -- those with fewer resources -- were ready to take significantly more risks the day before receiving welfare checks, when they are most likely to be below the threshold, than at other times.

In anthropology, Kuznar [@kuznar2001] presented evidence of a U-shape between herd value and risk taking -- but the small size of the sample (23 Andean farmers) limits statistical inference. Caballero [@caballero] estimated a subsistence threshold in extremely deprived neighbourhoods of Bogota, and found preliminary evidence of a jump in risk taking at that point. But again, the sample size was not sufficient to draw firm conclusions. In principle, though, any dataset that includes measures of resources and risk taking could be used to test the hypothesis, as long as there are enough people above and below the desperation threshold. In sum, there is some evidence from diverse populations of U- or V-shaped relationships between material resources and risk tolerance, but the number of studies is limited and many of them are based on small samples.

In this paper, we first offer a succinct formalization of the desperation threshold model, from which we derive the predicted non-linear relation between resources and risk taking. Then we test those predictions using the *Changing Cost of Living* dataset [@nettleShorttermChangesFinancial2023], a survey of British and French adults that includes questions about participants' levels of resources across time, as well as a measure of risk taking. Moreover, these questions concerned not only income, but also unavoidable costs and subjective feelings of poverty. Thus, we can test the prediction using an objective measure of resources, and a subjective one, the feeling of resource adequacy.

## Theory

The desperation threshold idea can be summarised as follows: humans have a strong preference for having at least some amount of resources that represent their 'basic needs'. Above this level, they continue to derive utility from resources, but this is less important than keeping their basic needs secured. We can formalise this threshold with a utility function. The initial set of models captured this idea with a jump in the utility function [@masson1974], or even a step function, representing life and death [@stephens1981]. Here, we assume a more general sigmoid shape. The utility function features a steep region, representing that at some point resources are particularly valuable because they secure basic needs. Below the threshold, the utility function is relatively flat, representing the intuition that one has 'little more to lose' once basic needs are not reached. Above the threshold, we assume that utility increases linearly with resources.

Our utility function is therefore: $$U(x) = \frac{1}{1+e^{-x}} + \frac{x}{50}\mathbb 1_{x>0},$$ where $x$ represents resources and the threshold is placed at 0 $\mathbb 1_{x>0}$ being an indicator function, whose value is 1 when $x>0$ and 0 otherwise. Figure 4.1A represents this utility function, and highlights the central result of the model. Below the threshold, the function is convex: one has more to win than to lose, and should therefore take risks. Above the threshold, the function is concave: one has more to lose than to win, and should therefore avoid risks. It should be noted that the desperation threshold does not predict a change in 'risk preference' strictly speaking from an economics point of view: the taste for risky outcomes is unchanged. Rather, Lybbert @lybbert2013 has coined the term of 'risk response' to threshold effects, which applies here. Thus, we use the terms 'risk taking' and 'risk avoidance', rather than 'risk proneness' and 'risk aversion'.

```{r, echo=FALSE, fig.width=10, fig.asp=.25, fig.align="default", dev="jpeg",dpi=300,fig.cap="Summary of the model and predictions. (A) is the  utility function we assume to represent the desperation threshold. (B) is the resulting certainty equivalent of the risky decision - the minimum guaranteed amount of money one would accept instead of taking a 50% chance to win €800 - depending on resources. Certainty equivalent being a measure of risk taking, this is the association we predict between risk taking and resources. (C) represents the same as panel B when resources are observed with a large noise (sd=€500) and certainty equivalents with a smaller noise (sd=€50). This is the basis of our second prediction, that risk taking should vary more among individuals with low resources."}
c = ggdraw() + draw_image('~/code/changing_cost_of_living_desperation/images/utility.png')
a = ggdraw() +
    draw_image("~/code/changing_cost_of_living_desperation/images/prediction_v.png")
b = ggdraw() +
    draw_image("~/code/changing_cost_of_living_desperation/images/prediction_noisy.jpg")
plot_grid(c,a,b,labels = c("A","B","C"),align="h",nrow=1)
```

In figure 4.1B, we plot the 'certainty equivalent' depending on resources. Concretely, we assume that an individual has the utility function shown in figure 4.1A and we let her decide between €$x$ for sure and a 50% chance of getting €800. We vary $x$ from 0 to 800 and we plot in figure 4.1B the minimum value of $x$ she would take. This represents the value she attributes to the risky choice, and can therefore be used as a measure of risk taking. If the certainty equivalent is more than 400, the person is taking risk; if it is less than 400, they are avoiding risk, and if it is exactly 400, they are risk neutral. In the task used in the Changing Cost of Living survey (see next section), the certainty equivalent represents the point where participants would switch to the safe option. The resulting prediction (figure 4.1B) is that below the threshold, people should take risks even when the expected value of the certain option is higher than that of the risky options, whereas just above the threshold they should avoid risks even when the certain payoff has a worse expected value than the risky option. Note that the switch to risk taking occurs below the threshold here, since participants can only gain resources in the task. The switch from risk avoidance to risk taking is reached around $x=-400$, where €400 with certainty means ending up precisely at the desperation threshold. Thus, our first prediction is that risk taking should be a V-shape function of resources (figure 4.1B).

Now, what if resources are only imperfectly observed? As risk taking varies abruptly with resources around the desperation threshold, it is crucual to tell apart individuals just above the threshold from those just below. In practice, this might not be realistic: resource levels are not perfectly measured, and the threshold may vary from individual to individual. In figure 4.1C, we present our prediction if resources are observed with a high noise (sd = €500) and certainty equivalents with a low noise (sd = €50). The V-shape is not visible to the naked eye anymore, but we obtain a triangle-shaped scatter plot. This is the basis of our second prediction: risk taking should be more variable in the lower part of the resource distribution than the higher part. This is because the lower part comprises some individuals just above and some individuals just below the threshold, with opposite levels of risk taking.

To sum up, the desperation threshold model makes two predictions. First, that risk taking should follow a V-shape of resource levels, with both the poorest and the richest participants taking more risks than average (P1). Second, that risk taking should vary more between individuals at low resource levels (P2), since one should find both 'vulnerable' participants avoiding risks, and 'desperate' ones taking risks. In the Analysis strategy subsection, we explain how we tested P1 and P2 using the *Changing Cost of Living* Dataset.

## Methods

```{r load_data, include=FALSE, message=FALSE}
load("~/Downloads/CCL_processed_data_v2.Rdata")
##Download the data here: https://osf.io/d9qb6/, and fill in the directory
d$total_bills = d$rent+d$counciltax+d$water+d$energy
d$resources = log((d$incomec+1)/(d$total_bills+1))
#d$resources = log(d$incomec+1)
z = d$resources %in% c(Inf,-Inf)
d$resources[z] = NA #We set to NA the resource variable of individuals who have income=0 or bills=0
d$subj_resources = scale(-sqrt(d$destitutionrisk+d$housingrisk+d$employmentrisk))[,1]
#d$resources = scale(d$resources)[,1]

d$risk_taking = rowSums(2-d[colnames(d)[45:51]])

#Impute the 9 values who missed just one risk question
# For those lines, we take the mean of the two closest answers, or the one closest if it's risk_1 or risk_7
z = which(rowSums(is.na(d[,45:51]))==1)
for(i in z){
  zz = which(is.na(d[i,45:51]))
  if(zz<7){
    d$risk_taking[i] = rowSums(2-d[i,colnames(d)[(45:51)[-zz]]]) + 2 - mean(c(as.integer(d[i,45:51][(zz-1)]),as.integer(d[i,45:51][(zz+1)])))
  }else{d$risk_taking[i] = rowSums(2-d[i,colnames(d)[(45:51)[-zz]]]) + 2 - as.integer(d[i,45:51][(zz-1)])}
}

library("psych")
library(tidyr)
d_risk = d[c("pid","risk_taking","month")] %>% spread(key="month","risk_taking")
icc = ICC(d_risk[-1])

d$risk_consistent2 = NA
for(i in 1:nrow(d)){
  d$risk_consistent2[i] = all(d[i,45:51] == cummax(unlist(d[i,45:51])))
}
```

### Panel

We used the data collected for the project *The Changing Cost of Living* study (for a complete description of this data collection, see [@nettleShorttermChangesFinancial2023]; protocols available at [https://osf.io/e8g3p](https://osf.io/e8g3p/)). The authors recruited in September 2022 a panel of 232 French and 240 British adults over the age of 25. Participants were invited to complete a survey once a month for 12 months. On average, participants completed 10.05 of the 12 surveys each (sd 2.98). In August 2023, when the study ended, 157 (67.7%) and 216 (90%) of the original participants responded. Table 4.2 shows participant demographics. The panels were not nationally representative, and were skewed towards the low end of their respective national income distributions, especially in France (see [@nettleShorttermChangesFinancial2023] for details).

### Measures

The full set of measures is described in the preregistered initial (<https://osf.io/x26mf>) and supplementary (<https://osf.io/rj683>) protocols of the study. The data were collected for multiple studies [in particular, @nettleShorttermChangesFinancial2023], and we only use some of its measures.

*Objective resources*. Participants reported the amount of income received into their household in the reference month (i.e., net of taxes and including benefits). UK figures were converted to euros at a purchasing-power parity rate. The mean income of participants was `r mean(d$incomec,na.rm=T) %>% round()`€ and the median `r median(d$income,na.rm=T)`€ (sd=`r sd(d$income,na.rm=T) %>% round(2)`). For costs, participants reported the amounts paid out for rent/mortgage, water, residence-based taxes, and energy (electricity, gas, oil) in the previous month. We summed these amounts to obtain an estimate of unavoidable living costs. We logged income and cost variables with a base 2 (adding €1 because of zeroes), to reduce positive skew and represent the fact that resources have diminishing returns. Our objective resources variable is the difference between the log-transformed income and log-transformed unavoidable costs. Since the difference in logs is the log of the ratio, this variable measures the proportional relationship of household income to unavoidable costs. Thus, a value of zero means that income just covered unavoidable costs; a value of 1 that income was twice unavoidable costs; and and a value of 2 means that income was four times unavoidable costs. Negative values (1.6% of cases) indicate failure of income to even cover unavoidable costs.

*Subjective resources*. Participants were asked three questions about their subjective risk of losing resources: their subjective risk of destitution, their subjective risk of losing "a suitable place to live", and their subjective risk of losing "a suitable employment". Participants answered these three questions on a 0-100 scale, which we summed and reverse coded to compute our subjective resources measure. The three variables had a Cronbach's alpha of `r cronbach(d[c("destitutionrisk","housingrisk","employmentrisk")])$alpha %>% round(2)`. To avoid right-skew (a large number of participants reported almost zero on those three measures), we applied a square root transformation. Subjective resources were moderately correlated with objective resources ($r =$ `r cor.test(d$resources,d$subj_resources)$estimate %>% round(2)`, p \< .001).

*Risk taking*. Participants were asked whether they preferred a 50% chance of getting €800, or €$x$ for sure, with $x$ being increased by €100 from €100 to €700. We used the number of risky bets (choosing 50% chance of getting €800) that participants preferred as our measure of risk taking. If participants were perfectly consistent, this measure would be proportional to the minimum certainty equivalent that we presented in Figure 1B. But it is more robust to a 'trembling hand' of the participants: if a participant mistakenly refuses the least risky bet, but is actually risk neutral, then our measure will almost be correct (3 instead of 4), while the minimum certainty equivalent would have yielded 1.

On average, participants accepted `r mean(d$risk_taking,na.rm=T) %>% round(2)` of the 7 bets (sd= `r sd(d$risk_taking,na.rm=T) %>% round(2)`). Participants were weakly-to-moderately stable over time in their risk taking: the intra-class correlation coefficient (ICC) was `r round(icc$results[1,2],2)`.

*Time-discounting* Participants were asked whether they preferred €100 now or €$x$ 90 days from now, with x ranging from 110 to 170. We used the number of immediate choices as our time discounting measure. We use this variable in our exploratory analysis (see below), for contrast with the results we obtained with risk taking.

### Analysis strategy

We first investigated descriptively the relationship between resources and risk taking. We then ran five confirmatory tests of our predictions relating risk taking to resource levels. These analyses were preregistered here: <https://osf.io/g4x8t/>. In the results section, we present each test twice, using respectively objective and subjective resources. We corrected p-values using the Holm-Bonferroni method to control the error rate. These tests are divided in two distinct groups, differing in their level of severity to test our hypothesis (see below). The two groups relate respectively to P1 and P2 (see Theory).

In our first group of analyses (analysis 1), we predicted that risk taking would follow a V-shape against resources. First, we fitted mixed effects polynomial models, to test for evidence of a non-linear relationship between resources and risk taking. Second, we fitted segmented linear models, to estimate the association below and after a 'changepoint', fitted with maximum likelihood. This approach is less standard in psychology, and has been judged problematic in exploratory analyses [@breit2023]. However, our analysis is confirmatory, and our model prediction is closer to a broken-stick relationship (Figure 4.1B) than a smooth polynomial. We constrained the model to have the two regression lines connected, by fitting the following formula: $risk\_taking = \beta_0 + \beta_1(r-cp)(r\le cp) + \beta_2(r-cp)(r> cp)+\text{controls}$, where $cp$ is the changepoint and $r$ stands for the resources. The polynomial and the segmented models are two different ways to represent the predicted V-shape. We see them as two different tests of the same prediction.

In these analyses, we included random effects of participants and fixed effects of age and gender, two variables known to influence risk taking [@daly2001; @dohmen2011].

Our second group of analyses (analysis 2) tested the less specific prediction, that risk taking should be more variable in individuals with fewer resources. Our reasoning here was as follows: our resource measures may be too noisy for discriminating when individuals are just below the threshold and when they are just above, especially since the threshold might vary between individuals. In this case, we might not be able to identify a single switch point between risk avoidance and risk taking, but we should still expect a mixture of risk takers and risk avoiders at the bottom of the resource distribution, whereas risk preference should be more homogenous higher in the distribution (Figure 4.1C). We therefore tested in three ways whether variance in risk taking was higher among individuals with fewer resources. Specifically, we tested:

```{=tex}
\begin{enumerate}[(i)]
  \item whether variance in risk taking was higher among individuals reporting that "managing financially is very difficult";
  \item whether squared residuals of a linear model were higher at the bottom of the resource distribution; and
  \item whether participants with lower resources were less stable over time in their risk taking.
\end{enumerate}
```
This second group of analyses represents a less severe test of the model than the third one, in the sense that the predicted result could be obtained under less stringent conditions, and, as a result, more alternative explanations could be proposed (see Discussion section).

Finally, we ran an exploratory analysis that was not preregistered. There, we used all the available resource variables to isolate the most deprived individuals, according to different criteria. We computed descriptive statistics of risk taking in these categories: the mean, variance, and frequency of extreme values, and compared them to the full sample population. We also contrasted the results with the ones obtained with richest individuals, and using time discounting instead of risk taking.

## Results

### Descriptive analysis

To visualize of how risk taking and resources were related, we plotted the average level of risk taking depending on the answer to the question "How are you managing financially?". We obtained (figure 4.5) an approximately linear, increasing trend: the easier to manage, the more risks, on average. This could however hide the fact that, as we suggested, those who report that managing financially is 'very difficult' include a minority of risk takers, hidden behind a majority of risk avoiders.

To investigate this possibility, we examined the average values on our two resource measures of people choosing each of the possible numbers of risky options (0-7). Figure 4.2 shows the results. An inverted V-shape is clear in both cases: both the participants who were ready to take *the least* and *the most* risks had on average fewer objective and subjective resources.

```{r echo=FALSE,warnings=FALSE,fig.align = 'center',out.width = "100%",dev="jpeg",dpi=300,fig.cap="Objective and subjective resources summarized by risk taking answer. In these plots, we have pooled together the participants who accepted six and seven risky bets, to have a large enough group. The error bars represent 1 standard error of the mean."}

#rm(results) #In case of rerun, avoid a bug
d$risks = round(d$risk_taking)
d$risks[d$risks>5] = 6
d$Foodbank = d$foodbank>1
d$foodinsecurity = !(d$FI2 > 1)
DV = c("resources","subj_resources")
#tidyr::gather(d[DV],"Variable","value",-risks)

pd <- position_dodge(0.1)
for(dv in DV){
  z = !is.na(d$risks)
  a = summarySE(d[z,],dv,~risks,na.rm=T)
  a$variable = dv
  colnames(a)[3] = "value"
  if(!exists("results")){results = a
  }else{
    results = rbind(results,a)
  }
}
z = results$variable %in% c("foodbank")
results$value[z] = max(d$foodbank,na.rm=T)-results$value[z]

var.labs = c("Objective Resources","Subjective Resources")
names(var.labs) = DV

scales <- list(scale_y_continuous(),scale_y_continuous()
  
  )

ggplot(results,aes(as.factor(risks),value)) + geom_point(position=pd) +
  geom_errorbar(aes(ymin=value-se, ymax=value+se), width=.1, position=pd) +
  facet_wrap(~variable,scales="free_y",labeller = labeller(variable=var.labs)) +
  
  facetted_pos_scales(y = scales) +
  theme_classic() + 
  xlab("Risk taking") + ylab("Resources") + theme(axis.title=element_text(size=14))

```

\newpage

```{r warning=FALSE, include=FALSE}

library(gtools)
mean_risk_taking = vector()
mean_risk_taking["population"] = mean(d$risk_taking,na.rm=T)
p_values_mean = vector()
p_values_mean["population"] = NA
prevalence_risk_taking = vector()
prevalence_risk_taking["population"] = mean(d$risk_taking > 4,na.rm=T)
prevalence_risk_avoiding = vector()
prevalence_risk_avoiding["population"] = mean(d$risk_taking == 0,na.rm=T)
p_values_prevalence = vector()
p_values_prevalence["population"] = NA
p_values_avoiding = vector()
p_values_avoiding["popoulation"] = NA
variance_in_risk_taking = vector()
variance_in_risk_taking["population"] = var(d$risk_taking,na.rm=T)
p_values_variance = vector()
p_values_variance["population"] = NA
n = vector()
n["population"] = nrow(d)

inconsistency = vector()
inconsistency["population"] = 1-mean(d$risk_consistent2,na.rm=T)

for(dv in c("resources","subj_resources")){
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],.95)
  mean_risk_taking[str_c(dv,"_top")] = mean(d$risk_taking[d[dv]>=a],na.rm=T)
  p_values_mean[str_c(dv,"_top")] = t.test(d$risk_taking[d[dv]>=a],d$risk_taking[d[dv]<a])$p.value
  prevalence_risk_taking[str_c(dv,"_top")] = mean(d$risk_taking[d[dv] >= a]>4,na.rm=T)
  p_values_prevalence[str_c(dv,"_top")] =chisq.test(table(d$risk_taking > 4,d[dv]>= a))$p.value
  prevalence_risk_avoiding[str_c(dv,"_top")] = mean(d$risk_taking[d[dv] >= a] == 0,na.rm=T)
  p_values_avoiding[str_c(dv,"_top")] =chisq.test(table(d$risk_taking == 0,d[dv]>= a))$p.value 
  variance_in_risk_taking[str_c(dv,"_top")] = var(d$risk_taking[d[dv]>= a],na.rm=T) 
  p_values_variance[str_c(dv,"_top")] = var.test(data=d,as.formula(glue("risk_taking~({dv}>=a)")))$p.value
  n[str_c(dv,"_top")] = sum(d[dv]>=a,na.rm=T)
}

for(dv in c("resources","subj_resources")){
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],.05)
  mean_risk_taking[dv] = mean(d$risk_taking[d[dv]<=a],na.rm=T)
  p_values_mean[dv] = t.test(d$risk_taking[d[dv]>a],d$risk_taking[d[dv]<=a])$p.value
  prevalence_risk_taking[dv] = mean(d$risk_taking[d[dv] <= a]>4,na.rm=T)
  p_values_prevalence[dv] = chisq.test(table(d$risk_taking > 4,d[dv]<= a))$p.value
  prevalence_risk_avoiding[dv] = mean(d$risk_taking[d[dv] <= a] == 0,na.rm=T)
  p_values_avoiding[dv] =chisq.test(table(d$risk_taking == 0,d[dv]<= a))$p.value 
  variance_in_risk_taking[dv] = var(d$risk_taking[d[dv]<= a],na.rm=T) 
  p_values_variance[dv] = var.test(data=d,as.formula(glue("risk_taking~({dv}<=a)")))$p.value
  n[dv] = sum(d[dv]<=a,na.rm=T)
  inconsistency[dv] = 1-mean(d$risk_consistent2[d[dv]<=a],na.rm=T)
}

p_values_mean = p.adjust(p_values_mean)
p_values_variance = p.adjust(p_values_variance)
p_values_prevalence = p.adjust(p_values_prevalence)
p_values_avoiding = p.adjust(p_values_avoiding)

Categories = c("Full sample","Top 5% in objective resources","Top 5% in subjective resources","Bottom 5% in objective resources","Bottom 5% in subjective resources")

results = data.frame(Categories,paste(round(mean_risk_taking,2),stars.pval2(p_values_mean)),
                     paste(round(variance_in_risk_taking,2),stars.pval2(p_values_variance)),
                     paste(round(100*prevalence_risk_taking,1),stars.pval2(p_values_prevalence)),
                     paste(round(100*prevalence_risk_avoiding,1),stars.pval2(p_values_avoiding)),
                     n)


colnames(results) = c("Categories","Mean risk taking","Variance in risk taking","% of risk takers","% of risk avoiders","n")

results_main_text = results[c("Categories","% of risk takers","% of risk avoiders","n")]

t_main_text = flextable(results_main_text[-c(2,3),])
t_main_text = set_caption(t_main_text,"Extreme risk taking prevalence among participants low on resources. Asterisks denote the p-values of tests comparing the category with the rest of the sample, using chi-squared tests. Asterisks represent significance levels: * p < 0.05; ** p < 0.01; *** p < 0.001",align_with_table = F)

t_main_text = autofit(t_main_text)
t_main_text = bold(t_main_text,i=1)
results_appendix = results
t_appendix = flextable(results)
t_appendix = fontsize(t_appendix, size = 11,part="header")

t_appendix = set_caption(t_appendix,"Risk taking statistics by resources categories",align_with_table = F)
t_appendix = add_footer_lines(t_appendix,"Asterisks denote the p-values of tests comparing the category with the rest of the sample, using t-tests to compare means, F-tests to compare variances and Chi-squared tests to compare prevalences. In each column, the set of p-values was corrected for multiple comparisons, using Holm-Bonferroni method. Asterisks represent significance levels: * p < 0.05; ** p < 0.01; *** p < 0.001")
t_appendix = autofit(t_appendix)
t_appendix = bold(t_appendix,i=1) 


mean_timediscounting = vector()
mean_timediscounting["population"] = mean(d$timediscounting,na.rm=T)
p_values_mean = vector()
p_values_mean["population"] = NA
prevalence_high_timediscounting = vector()
prevalence_high_timediscounting["population"] = mean(d$timediscounting == 7,na.rm=T)
prevalence_low_timediscounting = vector()
prevalence_low_timediscounting["population"] = mean(d$timediscounting == 0,na.rm=T)
p_values_prevalence = vector()
p_values_prevalence["population"] = NA
p_values_avoiding = vector()
p_values_avoiding["popoulation"] = NA
variance_in_timediscounting = vector()
variance_in_timediscounting["population"] = var(d$timediscounting,na.rm=T)
p_values_variance = vector()
p_values_variance["population"] = NA
n = vector()
n["population"] = nrow(d)


for(dv in c("resources","subj_resources")){
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],.95)
  mean_timediscounting[str_c(dv,"_top")] = mean(d$timediscounting[d[dv]>=a],na.rm=T)
  p_values_mean[str_c(dv,"_top")] = t.test(d$timediscounting[d[dv]>=a],d$timediscounting[d[dv]<a])$p.value
  prevalence_high_timediscounting[str_c(dv,"_top")] = mean(d$timediscounting[d[dv] >= a]== 7,na.rm=T)
  p_values_prevalence[str_c(dv,"_top")] =chisq.test(table(d$timediscounting == 7,d[dv]>= a))$p.value
  prevalence_low_timediscounting[str_c(dv,"_top")] = mean(d$timediscounting[d[dv] >= a] == 0,na.rm=T)
  p_values_avoiding[str_c(dv,"_top")] =chisq.test(table(d$timediscounting == 0,d[dv]>= a))$p.value 
  variance_in_timediscounting[str_c(dv,"_top")] = var(d$timediscounting[d[dv]>= a],na.rm=T) 
  p_values_variance[str_c(dv,"_top")] = var.test(data=d,as.formula(glue("timediscounting~({dv}>=a)")))$p.value
  n[str_c(dv,"_top")] = sum(d[dv]>=a,na.rm=T)
}

for(dv in c("resources","subj_resources")){
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],.05)
  mean_timediscounting[dv] = mean(d$timediscounting[d[dv]<=a],na.rm=T)
  p_values_mean[dv] = t.test(d$timediscounting[d[dv]<=a],d$timediscounting[d[dv]<a])$p.value
  prevalence_high_timediscounting[dv] = mean(d$timediscounting[d[dv] <= a]== 7,na.rm=T)
  p_values_prevalence[dv] =chisq.test(table(d$timediscounting == 7,d[dv]<= a))$p.value
  prevalence_low_timediscounting[dv] = mean(d$timediscounting[d[dv] <= a] == 0,na.rm=T)
  p_values_avoiding[dv] =chisq.test(table(d$timediscounting == 0,d[dv]<= a))$p.value 
  variance_in_timediscounting[dv] = var(d$timediscounting[d[dv]<= a],na.rm=T) 
  p_values_variance[dv] = var.test(data=d,as.formula(glue("timediscounting~({dv}<=a)")))$p.value
  n[dv] = sum(d[dv]<=a,na.rm=T)
}


p_values_mean = p.adjust(p_values_mean)
p_values_variance = p.adjust(p_values_variance)
p_values_prevalence = p.adjust(p_values_prevalence)
p_values_avoiding = p.adjust(p_values_avoiding)

Categories = c("Full sample","Top 5% in objective resources","Top 5% in subjective resources","Bottom 5% in objective resources","Bottom 5% in subjective resources")


results = data.frame(Categories,paste(round(mean_timediscounting,2),stars.pval2(p_values_mean)),
                     paste(round(variance_in_timediscounting,2),stars.pval2(p_values_variance)),
                     paste(round(100*prevalence_high_timediscounting,1),stars.pval2(p_values_prevalence)),
                     paste(round(100*prevalence_low_timediscounting,1),stars.pval2(p_values_avoiding)),
                     n)


colnames(results) = c("Categories","Mean time discounting","Variance in time discounting","% of high discount","% of low discount","n")
results_appendix_time_time_discounting = results
t_time_discounting = flextable(results)
t_time_discounting = fontsize(t_time_discounting, size = 10,part="header")
t_time_discounting = set_caption(t_time_discounting,"Time discounting statistics in extreme resources categories",align_with_table = F)
t_time_discounting = add_footer_lines(t_time_discounting,"Asterisks denote the p-values of tests comparing the category with the rest of the sample, using t-tests to compare means, F-tests to compare variances and κ-squared tests to compare prevalences. In each column, the set of p-values was corrected for multiple comparisons, using Holm-Bonferroni method. Asterisks represent significance levels: * p < 0.05; ** p < 0.01; *** p < 0.001")
t_time_discounting = autofit(t_time_discounting)
t_time_discounting = bold(t_time_discounting,i=1)
```

```{r echo=FALSE}
results_main_text_clean <- results_main_text[-c(2, 3), ]
kable(results_main_text_clean, row.names = FALSE, caption = "Extreme risk taking prevalence among participants low on resources. Asterisks denote the p-values of tests comparing the category with the rest of the sample, using chi-squared tests. Asterisks represent significance levels: \\*p < 0.05; \\*\\*p < 0.01; \\*\\*\\*p < 0.001.")
```



Finally, we looked at the prevalence of extreme risk taking among the 5% with the lowest levels of objective and subjective resources (Table 4.1). We defined participants as 'risk avoiders' when they accepted no bets, and as 'risk takers' when they accepted more than four bets. We use this term because a participant accepting more than four bets necessarily preferred a risky bet to a safe one that had a higher expected payoff (for instance, a 50% chance of getting 800€, rather than 500€ for sure). In Table 4.4, we expand this table, adding more descriptive statistics of risk taking.

Risk avoiders were more common in the bottom 5% than in the full sample. This was true whether resources were defined objectively or subjectively. Risk takers were also more common in the bottom 5% than the full sample. Again this was true whether objective or subjective resources were used, but it was particularly marked for subjective resources. The difference in prevalence of risk takers was only significant with subjective resources, but since risk takers were about three times rarer than risk avoiders, the power of these tests was much lower. Also, risk taking was on average lower (significantly for objective resources), but the variance in risk taking was respectively `r (100*((variance_in_risk_taking["resources"])/variance_in_risk_taking[1]-1)) %>% round()`% and `r (100*((variance_in_risk_taking["subj_resources"])/variance_in_risk_taking[1]-1)) %>% round()`% higher than in the full sample ($p < .001$ in both cases) (see Table 4.3).

### Analysis 1

#### Polynomial regressions

```{r polynoms, include=FALSE,echo=FALSE}
plots = list()
p_values_linear_quadratic = list()
p_values_linear_cubic = list()
p_values_quadratic_cubic = list()
chisq_values_linear_quadratic = list()
chisq_values_linear_cubic = list()
chisq_values_quadratic_cubic = list()
min = vector()
max = vector()
table_likelihood_ratio_tests = list()
aic = list()
plots = list()
for(dv in c("resources","subj_resources")){
  z = which(!is.na(d[dv]))
  model_cubic = lmer(data=d[z,],as.formula(glue("scale(risk_taking) ~ {dv} + I({dv}^2) + I({dv}^3) + scale(age) + mgender + (1|pid)")),REML=F)
  model_quadratic = lmer(data=d[z,],as.formula(glue("scale(risk_taking) ~ {dv} + I({dv}^2) + scale(age) + mgender + (1|pid)")),REML=F)
  model_linear = lmer(data=d[z,],as.formula(glue("scale(risk_taking) ~ {dv} + scale(age) + mgender + (1|pid)")),REML=F)
  model_intercept = lmer(data=d[z,],as.formula(glue("risk_taking ~ scale(age) + mgender + (1|pid)")),REML=F)
  p_values_quadratic_cubic[[dv]] = anova(model_quadratic,model_cubic,test ="LRT")[8][2,]
  p_values_linear_quadratic[[dv]] = anova(model_linear,model_quadratic,test ="LRT")[8][2,]
  p_values_linear_cubic[[dv]] = anova(model_linear,model_cubic,test ="LRT")[8][2,]
  chisq_values_quadratic_cubic[[dv]] = anova(model_quadratic,model_cubic,test ="LRT")$Chisq[2]
  chisq_values_linear_quadratic[[dv]] = anova(model_linear,model_quadratic,test ="LRT")$Chisq[2]
  chisq_values_linear_cubic[[dv]] = anova(model_linear,model_cubic,test ="LRT")$Chisq[2]
  aic[[dv]] = c(AIC(model_linear),AIC(model_quadratic),AIC(model_cubic))
  coefs = lme4::fixef(model_cubic)[1:4]
  d[,"prediction"] = coefs[1] + coefs[2]*d[,dv] + 
    coefs[3]*d[,dv]^3+ coefs[4]*d[,dv]^3
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],.005)
  b = quantile(d[dv][z],.995)
  min[dv] = min(d[(d[dv] >= a)&(d[dv] <=b),"prediction"],na.rm=T)
  max[dv] = max(d[(d[dv] >= a)&(d[dv] <=b),"prediction"],na.rm=T)
  plots[[dv]] = ggplot(d[(d[dv] >= a)&(d[dv] <=b),],aes(!!sym(dv),prediction)) + geom_line()+theme_linedraw()
}

p_values_linear_quadratic = p.adjust(p_values_linear_quadratic)
p_values_linear_cubic = p.adjust(p_values_linear_cubic)
p_values_quadratic_cubic = p.adjust(p_values_quadratic_cubic)

best_polynomial_order = vector() 
for(dv in c("resources","subj_resources")){
  deviances = list()
  for(i in 1:5){
    a = str_c(rep(glue("I({dv}^"),i),1:i,rep(")",i))
    a = paste(a,collapse = " +")
    model = lmer(data=d,as.formula(glue("risk_taking ~ {a} + age + mgender + (1|pid)")),REML=F)
    deviances[[i]] = AIC(model)
  }
  best_polynomial_order[dv] = which.min(deviances)
}
```

We fitted a cubic polynomial of resources on risk taking, with a random effect for participant and fixed effects for age and gender. Here and in all the following regression models, we found the usual association for age and gender, with women and older individuals taking fewer risks (for the linear model, we obtained $\beta =$ `r round(summary(model_linear)$coefficients["mgenderWoman",1],3)`, $p =$ `r round(summary(model_linear)$coefficients["mgenderWoman",5],3)` for woman, $\beta =$ `r round(summary(model_linear)$coefficients["scale(age)",1],3)`, $p=$ `r round(summary(model_linear)$coefficients["scale(age)",5],3)` for standardised age).

We predicted that the fitted polynomial would have an inflection point in the lower half of the resource distribution. This prediction was supported with subjective resources, but not with objective resources, which showed an almost linear relationship (Figure 4.3A & B). We predicted that a quadratic or cubic model would fit the association of resources to risk taking better than a linear one. For objective resources, this was not the case: both the quadratic and the cubic model had a higher AIC (`r aic$resources[2] %>% round(1)` and `r aic$resources[3] %>% round(1)` respectively) than the linear one (`r aic$resources[1] %>% round(1)`). Neither can reject the linear model in a likelihood ratio test ($\chi^2$= `r chisq_values_linear_quadratic[["resources"]] %>% round(3)`, $p=$ `r p_values_linear_quadratic[["resources"]] %>% round(3)` for the quadratic model, $\chi^2$= `r chisq_values_linear_quadratic[["resources"]] %>% round(3)`, $p=$ `r p_values_linear_cubic[["resources"]] %>% round(3)` for the cubic one). As a preregistered follow up analysis, we fitted higher degree polynomials, looking for the model with the least AIC. No model had a lower AIC than the linear one.

With subjective resources, a cubic model had a lower AIC (`r aic$subj_resources[3] %>% round(1)`) than the linear one (`r aic$subj_resources[1] %>% round(1)`), the quadratic one (`r aic$subj_resources[2] %>% round(1)`) and any higher degree model. However, the superior fit of the cubic model over the linear one was not significant in a likelihood ratio test (`r chisq_values_linear_cubic[["subj_resources"]] %>% round(3)`, $p=$ `r p_values_linear_cubic[["subj_resources"]] %>% round(3)`).

#### Segmented mixed models {#segmented}

We fitted segmented mixed models between resource variables and risk taking. The changepoint was fitted by maximum likelihood, testing all possible values to identify the breakpoint giving the smallest deviance, which is a smaller-is-better measure of model fit. In Figure 4.6, we plot the deviance of the model, depending on the changepoint location.

```{r segmented,include=FALSE,echo=FALSE}
#n_breakpoints = 10
tables = list()
proportion_below = list()
breakpoints_fitted = vector()
lr_test = list()
p_values_below = list()
p_values_after = list()
p_values_interaction = list()
plots_segmented = list()
plots_deviance = list()
for(dv in c("resources","subj_resources")){
  models = list()
  deviance = vector()
  z = !is.na(d[,dv])
  #a = quantile(d[dv][z],0)
  #b = quantile(d[dv][z],1) #We will look for a breakpoint so that each segment contains at least 5% of the data
  #breakpoints = seq(a,b,length.out = n_breakpoints)
  breakpoints = unique(d[z,dv]) %>% unlist()
  #breakpoints = breakpoints[1:10]
  for(breakpoint in breakpoints){
    model = lmer(data=d,as.formula(glue("scale(risk_taking) ~ I(({dv}<=breakpoint)*({dv}-breakpoint)) + I(({dv}>breakpoint)*({dv}-breakpoint)) + scale(age) + mgender + +(1|pid)")),REML = F)
    models = c(models,model)
    deviance = c(deviance,deviance(model))
  }
  plots_deviance[[dv]] = ggplot(data.frame(breakpoints,deviance),aes(breakpoints,deviance)) + geom_point() + theme_linedraw()
  breakpoint = breakpoints[which.min(deviance)]
  model = models[[which.min(deviance)]]
  model_neutral = lmer(data=d,as.formula(glue("scale(risk_taking) ~ {dv} + scale(age) + mgender + (1|pid)")),REML = F)
  a = summary(model)
  p_values_below[[dv]] = a$coefficients[2,5] 
  p_values_after[[dv]] = a$coefficients[3,5]
  tables[[dv]] = round(a$coefficients,3)
  lr_test = anova(model_neutral,model)$`Pr(>Chisq)`[2]
  breakpoints_fitted[[dv]] = breakpoint
  proportion_below[[dv]] = mean(d[dv] <= breakpoint,na.rm=T)
  prediction=Vectorize(function(x) {
  if(x < breakpoint)
    return(lme4::fixef(model)[1]- breakpoint*lme4::fixef(model)[2] + x*lme4::fixef(model)[2])
  else
    return(return(lme4::fixef(model)[1]- breakpoint*lme4::fixef(model)[3] + x*lme4::fixef(model)[3]))
    })
  d$prediction = NA
  z = which(!is.na(d[dv]))
  d$prediction[z] = prediction(unlist(d[z,dv]))
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],.005)
  b = quantile(d[dv][z],.995)
  br = breakpoints_fitted[[dv]]
  plots_segmented[[dv]] = ggplot(d[(d[dv] >= a)&(d[dv] <=b),],aes(!!sym(dv),prediction)) + geom_line()  +
        #geom_vline(aes(xintercept = br))+
    theme_linedraw()
  #geom_abline(aes(color="Before",intercept = lme4::fixef(model)[1]- breakpoint*lme4::fixef(model)[2],slope = lme4::fixef(model)[2])) + 
#          geom_abline(aes(color="After",intercept = lme4::fixef(model)[1] - breakpoint*lme4::fixef(model)[3],slope = sum(lme4::fixef(model)[3]))) + 

  ##Test interaction effects
  d["dv"] = d[dv] - breakpoint
  d$after = as.numeric(d["dv"] > 0)
  model_interaction = lmer(data=d,as.formula(glue("risk_taking ~  dv + dv:after +age + mgender + (1|pid)")),REML = F)
  p_values_interaction[[dv]] = summary(model_interaction)$coefficients[6,5]
  }

#p_values_below = p.adjust(p_values_below,method="holm")
#p_values_after = p.adjust(p_values_after,method="holm")
#p_values_interaction = p.adjust(p_values_interaction,method="holm")
```

\newpage



Tables 2 and 3 show the scaled coefficients and the associated significance two-sided t-tests, for objective and subjective resources respectively. Figures 3C and 3D show the patterns between resources and risk taking predicted by the fitted models. With objective resources, we obtained the predicted V-shape (see Figure 4.3C). The slope of the association was significantly different from zero above the changepoint, but not below. The changepoint was found at the extreme bottom of the distribution (`r round(100*(1-proportion_below[[1]]),1)`% of the observations are above).

With subjective resources, all our predictions were supported. We obtained a V-shape, with resources having a significantly negative effect below and significantly positive above the threshold. After correction for multiple comparison with objective resources, both tests remained significant ($p=$ `r p.adjust(p_values_below)[["subj_resources"]] %>% round(3)` and $p=$ `r p.adjust(p_values_after)[["subj_resources"]] %>% round(3)`). As predicted, the changepoint was found at the lower end of the resource distribution (`r round(100*proportion_below[[2]],1)`% of the data points are below it). The effect below the threshold was `r abs(round(tables[[2]][2,1]/tables[[2]][3,1]))` times stronger than the effect above the threshold. We had not predicted a stronger effect below the changepoint in our preregistration, but this is clearly an implication of the desperation threshold model (Figure 4.1A). Figure 4.6 revealed that one could account almost as well for the data with a slightly higher changepoint (11% of the data points were below it). As a robustness check, we checked that our predictions were also supported with this alternative changepoint. Table 4.3 presents the scaled coefficients of this model. A V-shape was also found, with a significant effect on both sides of the changepoint.

```{r echo=FALSE, fig.asp=1, dev="jpeg",dpi=300,fig.cap="Risk taking predictions by the nonlinear statistical models, with polynomial (first line) and segmented regressions (second lines).", fig.height=5, fig.width=5, message=FALSE, warning=FALSE}
a = plots[["resources"]] + xlab("") + ylab("Predicted risk taking") + theme_classic() + theme(      axis.title=element_text(size=12))
b = plots[["subj_resources"]] + xlab("") + ylab("") + theme_classic()

ranges = c(layer_scales(a)$y$range$range,layer_scales(b)$y$range$range)

a = a+ylim(min(ranges),max(ranges))
b = b+ylim(min(ranges),max(ranges))

c = plots_segmented[["resources"]] + xlab("Objective resources") + ylab("Predicted risk taking") + theme_classic() + theme(      axis.title=element_text(size=12))
dd = plots_segmented[["subj_resources"]] + xlab("Subjective resources") + ylab("") + theme_classic() + theme(      axis.title=element_text(size=12))

ranges = c(layer_scales(c)$y$range$range,layer_scales(dd)$y$range$range)

c = c+ylim(min(ranges),max(ranges))
dd = dd+ylim(min(ranges),max(ranges))

plot_grid(a,b,c,dd,labels = c("A","B","C","D"))
```

### Analysis 2: do individuals with low resources vary more in risk taking?

#### Is there more variance in risk taking among close-to-the-edge participants?


```{r echo=FALSE,message=FALSE,warning=FALSE,fig.cap = 'Variance in risk taking among participants, grouped by their answer in the "managing financially" question. The error bars represent a 50% confidence interval for the estimation of the variance, which corresponds approximately to ±1 standard error in the case of a mean.'}
p_values = list()
effect = list()
test_managing = var.test(data=d,risk_taking~(managing==1))
p_values["managing"] = test_managing$p.value %>% round(4)

for(dv in c("resources","subj_resources")){
    model_neutral = lm(data=d,as.formula(glue("scale(risk_taking) ~ scale({dv}) + scale(age) + mgender")))
    model = lm(scale(sqrt(abs(model_neutral$residuals)))~ scale(unlist(model_neutral$model[glue("scale({dv})")])))
    p_values[[dv]] = summary(model)$coefficients[2,4]
    effect[[dv]] = summary(model)$coefficients[2,1]
}
p_values = p.adjust(p_values,method="holm")
```

In our second analysis, we predicted that there would be more variance in risk taking at the bottom of the resources distribution. We tested this prediction using the financial strain question, the objective and the subjective resources variables. As predicted, individuals who report that managing financially is "very difficult" had a `r round(100*(var(d$risk_taking[d$managing==1],na.rm=T)/var(d$risk_taking[d$managing>1],na.rm=T)-1))`% higher variance in their risk taking answers (F(`r test_managing$parameter["num df"]`,`r test_managing$parameter["denom df"]`)= `r test_managing$statistic %>% round(2)`, $p$ `r p_values["managing"] %>% format.pval(eps=.001)`). This also applied, to a lesser extent, for people who reported that it was "quite difficult" to manage financially (Figure 4.5B).

To test the same question with our (continuous) resource variables, we fitted linear regressions between resources and risk taking, keeping age and gender as controls, but without a changepoint and without random effects, so as not to neutralise the between-individual variance. Then, we predicted that squared residuals would decrease with resources in a new linear regression, that is, that the absolute deviation from the line of best fit would be larger at the bottom of the resource distribution. Since this analysis tests for the same prediction as the one above using the financial strain question, we apply a Holm-Bonferroni correction to the three p-values. The prediction was clearly met for both objective and subjective resources ($\beta=$`r effect[[1]] %>% round(2)` and $\beta=$ `r effect[[2]] %>% round(2)` respectively, $p$`r format.pval(p_values[[1]],eps=.001)` and $p$`r format.pval(p_values[[2]],eps=.001)`).

```{r include=FALSE}

dv = "resources"
var_ratio_resources = vector()
up_resources = vector()
low_resources = vector()

for (i in 1:50){
  z = !is.na(d[,dv])
  a = quantile(d[dv][z],i/100,na.rm=T)
  test = var.test(data=d,risk_taking~(resources>a))
  var_ratio_resources = c(var_ratio_resources,test$statistic)
  up_resources = c(up_resources,test$conf.int[1])
  low_resources = c(low_resources,test$conf.int[2])
#print(var.test(data=d,risk_taking~(resources>a))$p.value< .05)
}


dv = "subj_resources"
var_ratio_subj_resources = vector()
up_subj_resources = vector()
low_subj_resources = vector()
z = !is.na(d[,dv])
for (i in 1:length(var_ratio_resources)){
  a = quantile(d[dv][z],i/100,na.rm=T)
  test = var.test(data=d,risk_taking~(subj_resources>a))
  var_ratio_subj_resources = c(var_ratio_subj_resources,test$statistic)
  up_subj_resources = c(up_subj_resources,test$conf.int[1])
  low_subj_resources = c(low_subj_resources,test$conf.int[2])
  #print(var.test(data=d,risk_taking~(subj_resources>a))$p.value< .05)
  }
var_ratio = data.frame("Objective resources"=var_ratio_resources,"Subjective resources"=var_ratio_subj_resources)
var_ratio$percentile = 1:nrow(var_ratio)

var_ratio = gather(var_ratio,"Measure","value",-percentile)
var_ratio$Measure = var_ratio$Measure %>% recode("Subjective.resources"="Subjective resources",                                              "Objective.resources"="Objective resources")
```

```{r, echo=FALSE,out.width = "70%",fig.align = 'center',dev="jpeg",dpi=300,fig.cap="Ratio of variances in risk taking below and above resource thresholds set at different levels, from the first percentile to the median. For any threshold, the difference in variance is significant ($p<.05$).",warning=FALSE}
ggplot(var_ratio,aes(percentile,value,linetype=Measure)) + geom_line() + geom_line() + xlab("Percentile threshold") + ylab("Ratio of variances") + expand_limits(y=1) +  theme_classic() + theme(legend.position = c(0.7, 0.7))

```

We visualised this effect by comparing variance in risk taking below and above some resource threshold, varying this threshold from the first percentile of the resource distribution to the median value (Figure 4.4). For any threshold below the median, the variance was at least `r 100*round(min(var_ratio$value) - 1,2)`% higher in the bottom part of the distribution. This variance soars as the threshold goes toward zero, in particular using subjective resources.

#### Are participants with low resources less stable over time in their risk taking?

Finally, we tested a slightly different prediction: participants with fewer resources should sometimes hover around the threshold, and should then alternate between taking and avoiding risks. We would thus expect that an individual with fewer resources will vary more in risk taking over time. We computed the intra-personal variance in risk taking over all time periods for every individual, and fitted a linear model between this variance over time and the average resource value.

```{r include=FALSE,echo=FALSE}
p_values = list()
effect = list()
for(dv in c("resources","subj_resources")){
  d_grouped = d %>% dplyr::group_by(pid) %>% dplyr::summarise(resources = log(mean(incomec+1,na.rm=T)/mean(total_bills+1,na.rm=T)),subj_resources = -sqrt(mean(destitutionrisk+housingrisk+employmentrisk,na.rm=T)),variance_risk_taking = var(risk_taking),risk_taking = mean(risk_taking),n_data_points = n())
  
  model = lm(data = d_grouped,as.formula(glue("scale((variance_risk_taking+1))~scale({dv})")))
  a = summary(model)
  p_values[[dv]] = a$coefficients[2,4]
  effect[[dv]] = a$coefficients[2,1]
}
p_values = p.adjust(p_values,method="holm")
```

For objective and subjective resources, the association was in the predicted direction. It was significant with objective resources (standardised $\beta=$ `r effect[[1]] %>% round(2)`, $p=$ `r p_values[[1]] %>% round(3)`), but not with subjective resources (standardised $\beta=$ `r effect[[2]] %>% round(3)`, $p=$ `r p_values[[2]] %>% round(3)`). We must note that the statistical power of these two tests was much lower than the previous ones: since they aggregated all the responses from the same individual, they are based on only `r nrow(d_grouped)` data points, against `r length(resid(model_neutral))` before.

### Ruling out alternative explanations

We were interested in knowing whether our finding was specific to participants with fewer resources and to risk taking. Therefore, we replicated Table 4.1 on the top 5% answers in terms of objective and subjective resources (Table 4.4, line 2 and 3), and using the time discounting variable of the dataset, instead of risk taking (Table 4.5). We preregistered this analysis as a follow up (<https://osf.io/54hfq>).

With time discounting, we predicted (i) that there would be more individuals with high time discounting (defined as choosing only immediate rewards), but (ii) not more individuals with low time discounting (defined as never choosing immediate rewards) in the deprived categories than in the full sample, and (iii) that similarly, variance would not be more than 30% higher (30% being the lowest difference we found in risk taking). In both categories, high time discounting was more than twice as frequent in the deprived categories. In the bottom 5% of objective resources, our two other predictions were not supported: variance in time discounting was `r round(100*(variance_in_timediscounting["resources"]/variance_in_timediscounting["population"]-1))`% higher than in the full sample, and low time discounting was slightly more frequent (`r round(100*prevalence_low_timediscounting["resources"],1)`%) than in the full sample (`r round(100*prevalence_low_timediscounting["population"],1)`%). With subjective resources, all predictions were supported: variance was `r (100*((variance_in_timediscounting["subj_resources"])/variance_in_timediscounting[1]-1)) %>% round()`% higher than in the full sample, and low time discounting was less frequent (`r round(100*min(prevalence_low_timediscounting["subj_resources"]),1)`%) than in the full sample (`r round(100*prevalence_low_timediscounting["population"],1)`%). Thus, it seems that our observation that low resources was associated with extreme risk taking was specific to risk taking, and did not reveal a tendency to make extreme decisions in other domains.

Finally, as another test of comprehension, we examined whether individuals with fewer resources were more likely to produce inconsistent answers in the risk questions. Among the full sample, we categorized `r round(100 - 100*mean(d$risk_consistent2,na.rm=T),1)`% of the answers as inconsistent, in the sense that the participant refused a bet that was more profitable than another bet they accepted. However, neither objective nor subjective resources were correlated with consistency ($r=$ `r cor.test(as.integer(d$risk_consistent2),d$resources)$estimate %>% round(2)` and $r=$ `r cor.test(as.integer(d$risk_consistent2),d$subj_resources)$estimate %>% round(2)`, respectively), providing no evidence for differences in comprehension.

## Discussion

### Summary of results

In a panel of adults from France and the UK, we investigated the association between (lack of) resources and risk taking. We found clear evidence that having low resources is associated with a higher variance in risk taking (Figure 4.4), and with a large increase in both extreme risk avoidance and extreme risk taking (Table 2). This result is so clear in our data that it seems surprising that it is not an established finding in the social sciences. This might be due to most social science research focusing on linear relations, and undersampling of individuals who are below the threshold. We look forward to future studies of the desperation threshold in other datasets on risk taking and future discounting as well as other domains of cognition and behavior.

Our finding that poverty is associated with both risk avoidance and risk taking is important for several reasons. First, as noted, it reconciles two opposing perspectives on poverty and risk taking, which [@banerjee2004] named 'vulnerability' and 'desperation'. In our sample, a larger proportion of individuals living in situations of poverty avoid risk, suggesting that they have 'too much to lose'. At the same time, a larger proportion declare themselves ready to take risks that are on average detrimental, suggesting they have 'little to lose'. We also proposed an explanation for why poverty could lead to either vulnerability or desperation: the 'desperation threshold', an hypothesis that is analogous to other social sciences theories [@winterhalder1999; @scott1977; @mishra2010; @barclay; @roumasset1971; @kunreuther1974; @lybbert2007]. Our study provides a new source of evidence for the desperation threshold model. Until now, tests of the model have mainly been conducted either (i) in a lab, where poverty (or more precisely, 'need') is artificially induced [@mishra2010; @pietras2001; @pietras2006; @pietras2008; @deditius-island2007; @rode1999; @radkani2023], or (ii) in populations where starvation is a realistic possibility [@mace1990; @maertens2014; @kuznar2001; @tucker2012; @caballero]. Our study suggests that a formally equivalent mechanism can apply in the real world to more affluent populations, and that 'desperate' risk taking can happen when starvation is unlikely.

The desperation threshold model makes a more precise prediction (P1): individuals should avoid risk just above a 'desperation threshold' yet seek risk below it (Figure 4.1B). Most previous real-world studies only searched for an increase in risk taking when poverty increased [@tucker2012; @caballero; @mace1990; @kohler1996]. In our study, we aimed to simultaneously test the increase and the decrease. Our findings clearly show that both risk taking and risk avoidance were more common among participants with the fewest resources (Table 2). Yet, the evidence for a V-shape was less clear: we obtained the predicted V-shape when using our subjective resources measure and a segmented regression model, but not when using our objective resources measure or a polynomial model. In our preregistration, we stated the expectation that we would be less likely obtain evidence for P1: it requires (i) our resource measure to be precise enough to tell apart individuals just-above the threshold from the ones just-below, and (ii) that the threshold itself does not vary too much between individuals.
Still, our Analysis 1 produced conflicting results: we only obtained the predicted V-shape when using subjective resources and a segmented model. Even though we did not anticipate it, we can propose *post-hoc* explanations for this finding. The segmented model might be better suited to test our hypothesis: it fits one relation on only the very bottom part of the resource distribution, while a polynomial regression fits the whole sample at once. Polynomial regressions can also be unreliable for making predictions for extreme values of the independent variable [@simonsohn2018], the case we are interested in here.

As for the measure, subjective resources produced more clear-cut results than objective resources in all analyses (Figure 4.2, Figure 4.4, Table 4.4, and -- on time discounting -- Table 4.5). This could mean that the subjective measure is simply a better measure of poverty, and that people are better than researchers at estimating their own situation. In particular, their self-assessment could take into account savings and anticipations of the future, whereas our objective measure did not. This echoes the recurrent finding that subjective socio-economic status is more predictive of health outcomes than objective socio-economic status [@pepper2014; @adler2000; @cohen2008]. This result is also reminiscent of a recent finding [@blasco2023], that in multiple European countries, "deprivation ceases to be correlated with income below a certain threshold (p. 1). Importantly, the desperation threshold might differ between individuals, as some individuals have higher needs. We tried to capture this in our objective measure, by dividing income by unavoidable costs. Yet, there are likely other 'needs' that were not measured. Our subjective measure might better incorporate those needs, since participants estimated for themselves their risk of lacking resources in the near future. Furthermore, our objective resources variable measures flows of resources over a month (income and unavoidable costs), but not stocks (capital). It could thus measure variations in resources, rather than the total amount of resources available, which determines whether an individual can make ends meet. In our sample, 1.6% of the answers have higher unavoidable costs than income over a month. Our objective measure places those answers at the very bottom of the resources distribution. Those points likely reflect an exceptional expense or an unusually low income over one month, which massively influences our objective measure -- probably more so than our subjective measure, which should also capture savings and anticipations of the future. Actually, it might be impossible for an extremely poor individual to spend more than she earns, if she has no savings and no options to borrow money. That being said, subjective measures of resources risk are influenced by psychological states, which brings a danger of circularity. It is possible, for instance, that some individuals are panicking because of some unmeasured factor, and therefore report both a higher readiness to take risks and a worse subjective financial situation. In this case, our results still suggest that high financial worries can produce both risk taking and risk avoidance, which is also a new finding.

### Alternative explanations

The desperation threshold model proposes that poverty causes variations in risk taking, but our data only provide evidence for associations. Yet, our finding that populations in poverty are 'polarized' in terms of risk taking, with a mixture of risk avoiders and risk takers, enriches the picture of the link between poverty and risk taking.

This result could be produced by different mechanisms. First, causality could be reversed. If risk taking was an entirely stable personality trait, one would expect extreme risk taking or risk aversion to produce a higher chance of poverty. Indeed, some of the most risk-prone individuals would end up very poor as the risks they took have not paid off, while the risk-averse individuals would refuse profitable opportunities, and end up poorer than average. However, risk taking is only weakly-to-moderately stable over time in our data (ICC = .48), in line with other findings [@schildberg-hörisch2018; @mata2018]. Moreover, there is evidence that short-term variations in resources can modify risk taking. Using the same data and measures, [@nettleShorttermChangesFinancial2023] found evidence that within-person reduction in the objective resources variable were associated with within-person reduction in risk taking. Recently, [@akesaka2023] also found that individuals most dependent on social security were ready to take more risks the week before welfare checks arrived.

Poverty could also produce our results through a different mechanism. For instance, a lower education or a lower cognitive capacity due to financial stress [@mani2013] could lead individuals with fewer resources to not understand the risk questions as well. Though, we did not find any evidence of an association between resources and consistency in risk answers (section 4.4). This class of explanation would also predict that individuals in poverty misunderstand other questions as well, and display extreme scores in other domains than risk taking. In our data, the "time discounting" questions were similar in terms of language, and allow for comparison. To test for this alternative explanation, we replicated our exploratory analysis using time discounting. Our results (section 4.4) suggest that among the most deprived participants, steep time discounting was more frequent, but flat time discounting less frequent, whereas the alternative explanation (i.e. more errors amongst participants with low resources) would predict both to be more frequent.

Our results could also be driven by measurement error: some participants may fill the survey less seriously, and report extreme levels of both resources and risk taking, in either direction. But if so, we would find the same phenomenon not only on time discounting, but also among the individuals with high objective resources. This was not the case: the top 5% in objective and subjective resources showed a lower variance in risk taking, and provided fewer extreme answers (Table 4.4).

### Limitations

The Changing Cost of Living sample was not representative of UK or French populations. There were no participants below the age of 25, and few over 45. Also, the recruitment via online participation platforms produced an oversampling of individuals with low incomes (for details, see @nettleShorttermChangesFinancial2023). This could have been an advantage to test our hypothesis, which requires a sufficient number of low income individuals to detect the pattern. To evaluate how generalisable our results are, future research should test our predictions in other populations, ideally from different regions with different levels of standard of living.

Our risk taking measure also has limitations. Hypothetical lotteries measures may have suboptimal external validity. They predict behaviors like portfolio choice, occupational choice, smoking, and migration @dohmen2011, but less well than "general risk questions", like "Are you generally a risk taking person or do you try to avoid risks?" [@dohmen2011; @frey2017]. This second measure also tends to be more stable over time, and have a higher 'convergent validity' - that is, better generalizes across domains of risk taking [@mata2018, @dohmen2011; @frey2017]. However, the 'desperation threshold' only applies to risks related to resources. It can make a clear prediction on hypothetical lotteries (figure 4.1B), but not on the general risk questions. Moreover, because our goal was to capture risk taking as a response to current material conditions rather than a lasting personality trait, the lower temporal stability is thus not an issue for our research question. The hypothetical gambles thus seemed appropriate for our study, even if imperfect, for example because they were not actually incentivized.

### Implications

Our study has important societal implications, both to explain and to remedy problems associated with poverty. In our data, people in poverty were more likely to (i) avoid risk even when it would, on average, benefit them, and to (ii) take risks even when it will, on average, be detrimental. In both cases, such individuals are further from 'expected payoff' decision-making, which is, by definition, optimal if one wants to maximize resources in the long term. In a way, the desperation threshold makes it optimal to make decisions that are long-term sub-optimal from a poverty-reduction perspective.

Concretely, Banerjee [@banerjee2004] points out that both 'poverty as vulnerability' and 'poverty as desperation' can lock people in poverty: if people in poverty have too much to lose, they refrain from investing; if they have little to lose, they have "no obvious reason to want to repay" (p.62) a loan, and therefore no one would lend them resources. In both cases, it is harder for them to escape poverty. In previous research in economics, risk aversion has often been deemed as the cause of suboptimal decisions -- in particular in agricultural economics, where it was proposed as the cause of field scattering (e.g, @mccloskey1976) or refusal to adopt new, more profitable, technologies [@morduch1990].

'Desperate risk taking' likely imposes major costs on individuals, communities, and society at large. When below the desperation threshold, our model predicts that people will take risks even when they have a negative expected payoff (Figure 4.1B). In our data, the proportion of participants ready to take such 'bad risks' was twice as high in the lowest 5% in subjective resources (Table 2). In reality, risks that people in poverty have access to are likely to fall into this category: they lack the money to invest in risky but profitable assets, and can only borrow with astronomically high interest rates [@banerjee2003]. Also, a desperate individual needs resources urgently, to fulfill a basic need. One way to obtain resources quickly without investing might be to engage in property crime. It is a particularly risky activity: it implies the fundamental uncertainty of being caught and punished.

In some cases, it is thus plausible that desperate risk taking takes the form of crime. Empirically, risk taking (measured by hypothetical lotteries) has indeed been found to strongly predict property crime [@epper2022]. Crime (and in particular property crime) is more frequent in deprived [@hsieh1993] or unequal [@kelly2000; @daly2016] populations, a phenomenon that some attribute to a 'little to lose' feeling [@daly1997; @brezina2008], or to "a mind-set in which offenders are seeking less to maximize their gains than to deal with a present crisis" [p. 167, @jacobscrime1999].

However, if we equate willingness to take risks and willingness to engage in property crime, our model and our data have a counter-intuitive prediction. It is possible that people in poverty are, on average, more law-abiding (risk taking is on average lower), and yet, most crime occurs there, since people ready to take extreme risks are mostly found among them (Figure 4.2). This could, in turn, create discrimination: people in poverty could be suspected and mistrusted more, even though the majority of them are on the contrary especially unlikely to engage in crime. In other words, the fact that a minority of people in poverty are in a situation where they have to take risks might create a stigma affecting other people also in poverty. This could generate the fact that poorer people are, empirically, trusted less @boon-falleur2023, even though they might be less likely to engage in unethical behavior [@piff2010; @piff2012].

Finally, the desperation threshold has implications for the welfare system. By helping to meet basic needs under any conditions, social security measures -- for instance, unemployment benefits or health insurance -- should alleviate the desperation thresholds, and therefore 'smoothen' individuals' utility function. This should reduce both extreme risk aversion (one has less to lose if there is a strong safety net) and extreme risk taking (desperation would become rarer, or non-existent). Empirically, both risk aversion [@schroyen2018] and crime rates [@rudolph2020] tend to be lower in countries that have a stronger welfare state, which may indicate that such smoothing indeed takes place.

## Funding and acknowledgements

The authors report no conflict of interest. BdC's contributions have been supported by the Agence Nationale de la Recherche (ANR-23-CE28-0005-01). WEF's contributions have been supported by the Dutch Research Council (V1.Vidi.195.130) and the James S. McDonnell Foundation (<https://doi.org/10.37717/220020502>). The Changing Cost of Living Study was funded by the French Agence Nationale de la Recherche (ANR-21-CE28-0009); the NIHR (Application Development Award: Universal Basic Income. Grant number: NIHR154451. Research Registry number: researchregistry8567); the University of York Cost of Living Research Group; and the UK Prevention Research Partnership (MR/S037527/1) collaboration, ActEarly. UK Prevention Research Partnership is funded by the British Heart Foundation, Cancer Research UK, Chief Scientist Office of the Scottish Government Health and Social Care Directorates, Engineering and Physical Sciences Research Council, Economic and Social Research Council, Health and Social Care Research and Development Division (Welsh Government), Medical Research Council, National Institute for Health Research, Natural Environment Research Council, Public Health Agency (Northern Ireland), The Health Foundation and Wellcome. The authors thank Ulysse Klatzmann, Camille Boissel and Aurélien Allard for their precious help.

## Data transparency and reproducibility

The data are available here: <https://osf.io/e8g3p/>. This article was written in R markdown, which makes the analyses and the plots reproducible inside the document. The code, and the python code used to produce Figure 4.1, can be found in this repository: <https://github.com/regicid/changing_cost_of_living_desperation>.

```{=tex}
\newpage
```
## Appendix
\newpage
```{r tableonen, echo=FALSE, warning=FALSE}
d$Gender = factor(d$mgender, levels=c("Woman", "Man", "Prefers not to say"))
d$Managing=recode(d$managing, `1` = "Finding it very difficult", `2` = "Finding it quite difficult", `3` = "Just about getting by", `4` = "Doing alright", `5` = "Living comfortably" )
d$Managing = factor(d$Managing, levels =c("Finding it very difficult", "Finding it quite difficult", "Just about getting by", "Doing alright", "Living comfortably"))
label(d$mgender) = "Gender"
d$Age = d$age
d$Age = d$age
label(d$age) = "Age"
label(d$Managing) = "Financial strain"
t1caption  <- "Demographic characteristics of the samples. Ns in this table represent numbers of participants. Variables are as reported in the first month of the study (September 2022). \n Financial strain is a self-report variable of how the participant is managing financially."
#t1footnote <- "Ns in this table represent numbers of participants. Variables are as reported in the first month of the study (September 2022). \n Financial strain is a self-report variable of how the respondent is managing financially."

table1(~ Gender + Age + Managing|country, data=subset(d, month=="22-Sep"), caption = t1caption)
```

\newpage

```{r fig_descr, echo=FALSE, fig.align = 'center',out.width = "70%",fig.cap="Mean and variance in risk taking for participants, grouped by their answer in the 'managing financially' question", warning=FALSE}
d$Managing = as.factor(d$managing)
levels(d$Managing) = c("Very difficult","Quite difficult","Getting by","Alright","Comfortable")
z = !is.na(d$risk_taking + d$managing)
a = summarySE(d[z,],"risk_taking",~Managing,na.rm=T)
pd <- position_dodge(0.1)
plot_a = ggplot(a,aes(Managing,risk_taking)) +
         geom_errorbar(aes(ymin=risk_taking-se, ymax=risk_taking+se), width=.1, position=pd) +
           geom_point(position=pd) + theme_linedraw() + ylab("Mean")+ theme(      axis.title=element_text(size=14)) + 
          xlab("") + theme(axis.text=element_text(size=12),axis.text.x = element_text(size=0))

d$risks = d$risk_taking
d$residuals = NA
z = !is.na(d$risk_taking+d$age+as.numeric(as.factor(d$mgender)))
d$residuals[z] = lm(data=d,as.formula(glue("risk_taking~age+mgender")))$residuals
a = data.frame(var_in_risk_taking=NA,inf=NA,sup=NA)
z = !is.na(d$residuals+d$managing)
pd <- position_dodge(0.1)
for(i in 1:5){
  a[i,] = VarCI(d$residuals[z][d$managing[z]==i],conf.level = .5)
}
a$Managing = unique(d$Managing[z])[5:1]
#a = summarySE(d[z,],"residuals",~Managing,na.rm=T)
plot_b = ggplot(a,aes(Managing,var_in_risk_taking)) +
        geom_errorbar(aes(ymin=inf, ymax=sup), width=.1, position=pd) + ylab("Variance") + xlab("How well are you managing financially?") +
          geom_point(position = pd) + theme_light() + theme(axis.text.x = element_text(angle = 45, hjust=1)) + theme(      axis.title=element_text(size=14),axis.text=element_text(size=12))

plot_grid(plot_a,plot_b,nrow=2,rel_heights = c(1.5,2),labels = c("A","B"))
```

```{r echo=FALSE,message=FALSE,fig.align = 'center',warning = FALSE,out.width = "70%",fig.cap="Deviance of the statistical models depending on the changepoint location, using objective (A) and subjective (B) resources"}
a = plots_deviance[["subj_resources"]] + xlab("Subjective resources") + ylab("Deviance")
b = plots_deviance[["resources"]] + xlab("Objective resources") + ylab("Deviance")
plot_grid(b,a,labels=c("A","B"),nrow=2)

```



```{r echo=FALSE,message=FALSE,results="asis",warning=FALSE}
dv = "resources"
colnames(tables[[dv]])[5] = "p-value"
rownames(tables[[dv]]) = c("Intercept","Objective Resources (before changepoint)","Objective Resources (after changepoint)","Age","Gender: prefers not to say or self-describe","Gender: woman")
a = tables[[dv]]
a[,5] = paste(a[,5],stars.pval2(a[,5])[1:6])
a[,"df"] = round(as.numeric(a[,"df"]))

kable(as.data.frame(a) %>% rownames_to_column("Variable"), row.names = FALSE, caption = "Standardised coefficients of the segmented regression using objective resources as independent variable.")


```


```{r echo=FALSE,message=FALSE,results="asis",warning=FALSE}
dv = "subj_resources"
colnames(tables[[dv]])[5] = "p-value"
rownames(tables[[dv]]) = c("Intercept","Objective Resources (before changepoint)","Objective Resources (after changepoint)","Age","Gender: prefers not to say or self-describe","Gender: woman")
a = tables[[dv]]
a[,5] = paste(a[,5],stars.pval2(a[,5])[1:6])
a[,"df"] = round(as.numeric(a[,"df"]))
kable(as.data.frame(a) %>% rownames_to_column("Variable"), row.names = FALSE, caption = "Standardised coefficients of the segmented regression using subjective resources as independent variable.")

```


```{r echo=FALSE}
a = data.frame(breakpoints,deviance)
a = a[a$breakpoints> -1.5,]
z = which.min(a$deviance)
breakpoint = a$breakpoints[z]
model = lmer(data=d,as.formula(glue("scale(risk_taking) ~ I((subj_resources<=breakpoint)*(subj_resources-breakpoint)) + I((subj_resources>breakpoint)*(subj_resources-breakpoint)) + scale(age) + mgender + +(1|pid)")),REML = F)

a = summary(model)
table = round(a$coefficients,3)
dv = "subj_resources"
colnames(table)[5] = "p-value"
rownames(table) = c("Intercept","Subjective Resources (before changepoint)","Subjective Resources (after changepoint)","Age","Gender: prefers not to say or self-describe","Gender: woman")
table[,"df"] = round(table[,"df"])
a = table
a[,5] = paste(a[,5],stars.pval2(a[,5])[1:6])

kable(as.data.frame(a) %>% rownames_to_column("Variable"), row.names = FALSE, caption = "Standardised coefficients of the model using subjective resources as independent variable, and the alternative changepoint.")
```


\newpage
```{r echo=FALSE}
kable(results_appendix, row.names = FALSE, caption = "Risk taking statistics by resources categories. Asterisks denote the p-values of tests comparing the category with the rest of the sample, using t-tests to compare means, F-tests to compare variances and Chi-squared tests to compare prevalences. In each column, the set of p-values was corrected for multiple comparisons, using Holm-Bonferroni method. Asterisks represent significance levels: \\* p < 0.05; \\*\\* p < 0.01; \\*\\*\\* p < 0.001.")
```






\newpage
```{r echo=FALSE}
kable(results_appendix_time_time_discounting, row.names = FALSE, caption = "Time discounting statistics in extreme resources categories. Asterisks denote the p-values of tests comparing the category with the rest of the sample, using t-tests to compare means, F-tests to compare variances and Chi-squared tests to compare prevalences. In each column, the set of p-values was corrected for multiple comparisons, using Holm-Bonferroni method. Asterisks represent significance levels: \\* p < 0.05; \\*\\* p < 0.01; \\*\\*\\* p < 0.001.")

```


